{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fiftyone"
      ],
      "metadata": {
        "id": "qn9Jv3ZHLO6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "from torchvision import transforms\n",
        "from pycocotools.coco import COCO\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import fiftyone.zoo as foz\n",
        "from torchvision.io.image import read_image\n",
        "from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights, lraspp_mobilenet_v3_large, LRASPP_MobileNet_V3_Large_Weights\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchvision.models import resnet50, ResNet50_Weights, alexnet, AlexNet_Weights\n",
        "from torchvision.ops import deform_conv2d\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from __future__ import print_function\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import argparse\n",
        "from torch.optim import Adam\n",
        "import PIL.Image\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms.functional import to_pil_image, to_grayscale, to_tensor\n",
        "import random"
      ],
      "metadata": {
        "id": "lKaNNaoPLTBr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementaion of Deformable Convolution"
      ],
      "metadata": {
        "id": "S34nrsBPimTu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kQOCUASPUqHd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DeformableConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False):\n",
        "        super(DeformableConv2d, self).__init__()\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.padding = padding\n",
        "\n",
        "        self.offset_conv = nn.Conv2d(in_channels, 2 * kernel_size * kernel_size,\n",
        "                                     kernel_size=kernel_size, stride=stride, padding=self.padding, bias=True).to(device)\n",
        "\n",
        "        nn.init.kaiming_normal_(self.offset_conv.weight, nonlinearity='relu')\n",
        "        nn.init.constant_(self.offset_conv.bias, 0.)\n",
        "\n",
        "\n",
        "        self.modulator_conv = nn.Conv2d(in_channels, 1 * kernel_size * kernel_size,\n",
        "                                        kernel_size=kernel_size, stride=stride, padding=self.padding, bias=True).to(device)\n",
        "\n",
        "        nn.init.kaiming_normal_(self.modulator_conv.weight, nonlinearity='relu')\n",
        "        nn.init.constant_(self.modulator_conv.bias, 0.)\n",
        "\n",
        "\n",
        "        self.regular_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                      kernel_size=kernel_size, stride=stride, padding=self.padding, bias=bias).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, w = x.shape[2:]\n",
        "        max_offset = max(h, w)\n",
        "\n",
        "        offset = self.offset_conv(x).clamp(-max_offset, max_offset).to(device)\n",
        "        modulator = 2. * torch.sigmoid(self.modulator_conv(x)).to(device)\n",
        "\n",
        "        grid = self.generate_grid(offset, x.shape).to(device)\n",
        "\n",
        "        x = F.grid_sample(x, grid, mode='bilinear', padding_mode='border')\n",
        "\n",
        "        x = self.regular_conv(x).to(device)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def generate_grid(self, offset, shape):\n",
        "\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        batch_size, channel, height, width = shape\n",
        "\n",
        "        h_range = torch.arange(0, height).view(1, height, 1).expand(batch_size, -1, width).to(device)\n",
        "        w_range = torch.arange(0, width).view(1, 1, width).expand(batch_size, height, -1).to(device)\n",
        "\n",
        "        offset = offset / max(height, width)\n",
        "        offset = offset.permute(0, 2, 3, 1).contiguous().to(device)\n",
        "\n",
        "        grid = torch.stack([w_range + offset[..., 0], h_range + offset[..., 1]], dim=-1).to(device)\n",
        "\n",
        "        grid = 2.0 * grid / max(height, width) - 1.0\n",
        "\n",
        "        return grid\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "classes = ['bicycle', 'car', 'cat', 'chair', 'cow', 'dog', 'horse', 'person', 'sheep']\n"
      ],
      "metadata": {
        "id": "mZK2cOvVLcZn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Define the CNN model\n",
        "class SimpleCNNN(nn.Module):\n",
        "    def __init__(self, classes, deformable=False):\n",
        "        super(SimpleCNNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        conv = nn.Conv2d if deformable==False else DeformableConv2d\n",
        "        self.conv4 = conv(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv5 = conv(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        #self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(32, len(classes)),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "          x = torch.relu(self.conv1(x))\n",
        "          x = self.pool(x) # [112, 112]\n",
        "          x = torch.relu(self.conv2(x))\n",
        "          x = self.pool(x) # [56, 56]\n",
        "          x = torch.relu(self.conv3(x))\n",
        "          x = torch.relu(self.conv4(x))\n",
        "          x = torch.relu(self.conv5(x))\n",
        "          x = self.gap(x)\n",
        "          x = x.flatten(start_dim=1)\n",
        "          x = self.fc(x)\n",
        "          return x\n",
        "\n",
        "class COCO(Dataset):\n",
        "    def __init__(self, datasets, classes, transforms=None):\n",
        "        self.dataset = datasets\n",
        "        self.classes = classes\n",
        "        self.transform = transforms\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.dataset[idx]\n",
        "        image = Image.open(sample.filepath).convert('RGB')\n",
        "\n",
        "\n",
        "        label = np.zeros(len(self.classes), dtype=np.float32)\n",
        "\n",
        "        for detection in sample.ground_truth.detections:\n",
        "            if detection.label in classes:\n",
        "                label[classes.index(detection.label)] = 1.0\n",
        "        image = self.transform(image)\n",
        "\n",
        "        label = torch.tensor(label, dtype=torch.float64)\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "pWZC0XNQUrhH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"train\",\n",
        "    label_types=[\"segmentations\"],\n",
        "    classes=classes,\n",
        "    max_samples=15000,\n",
        ")\n",
        "dataset_train = list(dataset_train)\n",
        "\n",
        "\n",
        "dataset_test = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"validation\",\n",
        "    label_types=[\"segmentations\"],\n",
        "    classes=classes,\n",
        "    max_samples=3000,\n",
        ")\n",
        "dataset_test = list(dataset_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "GREnj_vNMiDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db8fa67b-a7b8-466a-efee-2c1ad2f4491b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found annotations at '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Found annotations at '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sufficient images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Sufficient images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing download of split 'train' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Existing download of split 'train' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading existing dataset 'coco-2017-train-15000'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading existing dataset 'coco-2017-train-15000'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sufficient images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Sufficient images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing download of split 'validation' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Existing download of split 'validation' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading existing dataset 'coco-2017-validation-3000'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading existing dataset 'coco-2017-validation-3000'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "trainset = COCO(datasets=dataset_train, classes=classes, transforms=transforms)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testset = COCO(datasets=dataset_test, classes=classes, transforms=transforms)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "Jt9ovg4lP8_G"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model on COCO Dataset using Deformabale Convolution"
      ],
      "metadata": {
        "id": "l2ySSgvv9lbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNNN(classes, deformable=True).to(device)\n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.8)\n",
        "\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    overall_accuracy = 0\n",
        "    accuracy_per_label = torch.zeros(len(classes), device=device)\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "\n",
        "        correct_predictions = (preds == labels).float()\n",
        "\n",
        "        accuracy_per_label += correct_predictions.sum(0)/(len(labels))\n",
        "\n",
        "        overall_accuracy += correct_predictions.sum()/(len(labels)*(len(classes)))\n",
        "\n",
        "    accuracy_per_label /= len(trainloader)\n",
        "    running_loss /= len(trainloader)\n",
        "    overall_accuracy /= len(trainloader)\n",
        "\n",
        "    print(f'Train Loss: {running_loss:.4f} Total Acc: {overall_accuracy:.4f}')\n",
        "    print('Per Class Acc:', accuracy_per_label.tolist())\n",
        "\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LDkMnDxoVG3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dedccbd8-4a4c-436c-b288-0d86d43fc595"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3034 Total Acc: 0.9001\n",
            "Per Class Acc: [0.9587746858596802, 0.8161855936050415, 0.9303054213523865, 0.816560685634613, 0.9439663290977478, 0.944650411605835, 0.9589954614639282, 0.7860389947891235, 0.945025622844696]\n",
            "Train Loss: 0.2614 Total Acc: 0.9177\n",
            "Per Class Acc: [0.9615113139152527, 0.8435513973236084, 0.9500132203102112, 0.8417417407035828, 0.976165235042572, 0.9454890489578247, 0.9625927209854126, 0.7974046468734741, 0.9812632203102112]\n",
            "Train Loss: 0.2549 Total Acc: 0.9178\n",
            "Per Class Acc: [0.9617981910705566, 0.8444341421127319, 0.9497263431549072, 0.8400202989578247, 0.9770259261131287, 0.9446283578872681, 0.9623058438301086, 0.7987067699432373, 0.9813294410705566]\n",
            "Train Loss: 0.2505 Total Acc: 0.9179\n",
            "Per Class Acc: [0.9617981910705566, 0.8433085680007935, 0.9500132203102112, 0.8417637944221497, 0.9767390489578247, 0.9454890489578247, 0.9623058438301086, 0.7979784607887268, 0.9813294410705566]\n",
            "Train Loss: 0.2469 Total Acc: 0.9179\n",
            "Per Class Acc: [0.9615113139152527, 0.8441030979156494, 0.9500132203102112, 0.841454803943634, 0.9770259261131287, 0.9454890489578247, 0.9625927209854126, 0.7983315587043762, 0.980755627155304]\n",
            "Train Loss: 0.2441 Total Acc: 0.9179\n",
            "Per Class Acc: [0.9617981910705566, 0.844147264957428, 0.9500132203102112, 0.8412782549858093, 0.9767390489578247, 0.9454890489578247, 0.9620188474655151, 0.7987067699432373, 0.9810425639152527]\n",
            "Train Loss: 0.2426 Total Acc: 0.9178\n",
            "Per Class Acc: [0.9617981910705566, 0.8426465392112732, 0.9500132203102112, 0.8416755199432373, 0.976959764957428, 0.9454890489578247, 0.9622396230697632, 0.7979342937469482, 0.9813294410705566]\n",
            "Train Loss: 0.2401 Total Acc: 0.9182\n",
            "Per Class Acc: [0.9615113139152527, 0.8436617255210876, 0.9500132203102112, 0.8418079614639282, 0.9770259261131287, 0.9457759261131287, 0.9625927209854126, 0.8003178238868713, 0.9810425639152527]\n",
            "Train Loss: 0.2390 Total Acc: 0.9182\n",
            "Per Class Acc: [0.9617981910705566, 0.8435513973236084, 0.9497263431549072, 0.8426686525344849, 0.9770259261131287, 0.945202112197876, 0.9625927209854126, 0.7998543381690979, 0.9813294410705566]\n",
            "Train Loss: 0.2376 Total Acc: 0.9181\n",
            "Per Class Acc: [0.961224377155304, 0.842801034450531, 0.9500132203102112, 0.8418079614639282, 0.976959764957428, 0.9454890489578247, 0.9625927209854126, 0.8010240197181702, 0.9813294410705566]\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "    overall_accuracy = 0\n",
        "    accuracy_per_label = torch.zeros(len(classes), device=device)\n",
        "\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "        correct_predictions = (preds == labels).float()\n",
        "\n",
        "        accuracy_per_label += correct_predictions.sum(0)/(len(labels))\n",
        "\n",
        "        overall_accuracy += correct_predictions.sum()/(len(labels)*(len(classes)))\n",
        "\n",
        "    accuracy_per_label /= len(testloader)\n",
        "\n",
        "    overall_accuracy /= len(testloader)\n",
        "\n",
        "    print(f'Total Acc: {overall_accuracy:.4f}')\n",
        "    print('Per Class Acc:', accuracy_per_label.tolist())\n"
      ],
      "metadata": {
        "id": "IaseLX9hVGxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57fd41cc-a47e-41c4-c821-1d25be55673c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Acc: 0.9148\n",
            "Per Class Acc: [0.9541223049163818, 0.8457446694374084, 0.9457003474235535, 0.8310062289237976, 0.9746232032775879, 0.948803186416626, 0.9614361524581909, 0.7898935675621033, 0.9816045761108398]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNNN(classes, deformable=False).to(device)\n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.8)\n",
        "\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    overall_accuracy = 0\n",
        "    accuracy_per_label = torch.zeros(len(classes), device=device)\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "\n",
        "        correct_predictions = (preds == labels).float()\n",
        "\n",
        "        accuracy_per_label += correct_predictions.sum(0)/(len(labels))\n",
        "\n",
        "        overall_accuracy += correct_predictions.sum()/(len(labels)*(len(classes)))\n",
        "\n",
        "    accuracy_per_label /= len(trainloader)\n",
        "    running_loss /= len(trainloader)\n",
        "    overall_accuracy /= len(trainloader)\n",
        "\n",
        "    print(f'Train Loss: {running_loss:.4f} Total Acc: {overall_accuracy:.4f}')\n",
        "    print('Per Class Acc:', accuracy_per_label.tolist())\n",
        "\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB4B4pX491Xx",
        "outputId": "c71fb23c-ebf8-461d-f284-7d8399ee5582"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3134 Total Acc: 0.9013\n",
            "Per Class Acc: [0.9578698873519897, 0.828522264957428, 0.8886167407035828, 0.8382768034934998, 0.9751721620559692, 0.9277895092964172, 0.9314088821411133, 0.7922184467315674, 0.9722369313240051]\n",
            "Train Loss: 0.2695 Total Acc: 0.9177\n",
            "Per Class Acc: [0.961224377155304, 0.8420506715774536, 0.9500132203102112, 0.8416755199432373, 0.9767390489578247, 0.9457759261131287, 0.9620188474655151, 0.7987729907035828, 0.980755627155304]\n",
            "Train Loss: 0.2646 Total Acc: 0.9176\n",
            "Per Class Acc: [0.9615113139152527, 0.8441693186759949, 0.949373185634613, 0.8419403433799744, 0.976165235042572, 0.9446283578872681, 0.9623058438301086, 0.7976253032684326, 0.9810425639152527]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "    overall_accuracy = 0\n",
        "    accuracy_per_label = torch.zeros(len(classes), device=device)\n",
        "\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "        correct_predictions = (preds == labels).float()\n",
        "\n",
        "        accuracy_per_label += correct_predictions.sum(0)/(len(labels))\n",
        "\n",
        "        overall_accuracy += correct_predictions.sum()/(len(labels)*(len(classes)))\n",
        "\n",
        "    accuracy_per_label /= len(testloader)\n",
        "\n",
        "    overall_accuracy /= len(testloader)\n",
        "\n",
        "    print(f'Total Acc: {overall_accuracy:.4f}')\n",
        "    print('Per Class Acc:', accuracy_per_label.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7yGxTiC94Y2",
        "outputId": "bcdfec7c-0b27-40f4-9174-3a53efbd6b22"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Acc: 0.9145\n",
            "Per Class Acc: [0.9541223049163818, 0.8454121947288513, 0.9457003474235535, 0.8310062289237976, 0.9746232032775879, 0.948803186416626, 0.9614361524581909, 0.7878988981246948, 0.9816045761108398]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model on COCO Dataset using Normal Convolution"
      ],
      "metadata": {
        "id": "3IDJJ59e9yNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test on MNIST Dataset"
      ],
      "metadata": {
        "id": "lkCp_cT22PJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Required Classes and functions"
      ],
      "metadata": {
        "id": "G1l7t4D1gzPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've written a convolutional neural network (CNN) model for classifying MNIST digits. My model, defined in the `MNISTClassifier` class, is composed of several convolutional layers, pooling layers, and a fully connected layer for output. I've also implemented a `train` function that trains my model using a given dataset, optimizer, and loss function. To evaluate the performance of my model, I use the `test` function, which calculates the average loss and accuracy on a test dataset. A unique aspect of my testing procedure is that I scale the input data by different factors to assess the model's robustness to scale variations."
      ],
      "metadata": {
        "id": "XF_4WiPihvHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 deformable=False):\n",
        "\n",
        "        super(MNISTClassifier, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        conv = nn.Conv2d if deformable==False else DeformableConv2d\n",
        "        self.conv4 = conv(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv5 = conv(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.pool(x) # [14, 14]\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool(x) # [7, 7]\n",
        "        x = torch.relu(self.conv3(x))\n",
        "        x = torch.relu(self.conv4(x))\n",
        "        x = torch.relu(self.conv5(x))\n",
        "        x = self.gap(x)\n",
        "        x = x.flatten(start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train(model, loss_function, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_function(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def test(model, loss_function, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    num_data = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            org_data, target = data.to(device), target.to(device)\n",
        "\n",
        "            for scale in np.arange(0.5, 1.6, 0.1): # [0.5, 0.6, ... ,1.2, 1.3, 1.4, 1.5]\n",
        "                data = transforms.functional.affine(org_data, scale=scale, angle=0, translate=[0,0],shear=0)\n",
        "                output = model(data)\n",
        "                test_loss += loss_function(output, target).item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "                num_data += len(data)\n",
        "\n",
        "    test_loss /= num_data\n",
        "\n",
        "    test_acc = 100. * correct / num_data\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, num_data,\n",
        "        test_acc))\n",
        "    return test_acc\n"
      ],
      "metadata": {
        "id": "3RFnB04W2Ua_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model with `Normal Convolution`"
      ],
      "metadata": {
        "id": "a5kMuV5yh9M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "batch_size = 64\n",
        "lr=1e-3\n",
        "gamma=0.7\n",
        "epochs=14\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "train_transform = transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "dataset1 = datasets.MNIST('./data', train=True, download=True,\n",
        "                    transform=train_transform)\n",
        "dataset2 = datasets.MNIST('./data', train=False,\n",
        "                    transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset1, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset2, batch_size=64, shuffle=True)\n",
        "\n",
        "model = MNISTClassifier(deformable=False).to(device)\n",
        "optimizer = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=gamma)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "best_test_acc = 0.\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(model, loss_function, device, train_loader, optimizer, epoch)\n",
        "    best_test_acc = max(best_test_acc, test(model, loss_function, device, test_loader))\n",
        "    scheduler.step()\n",
        "print(\"best top1 acc(%): \", f\"{best_test_acc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kLRHudr37Ji",
        "outputId": "5013bed2-ca82-4249-88ac-840021275e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0164, Accuracy: 80101/110000 (72.82%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0143, Accuracy: 83113/110000 (75.56%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0086, Accuracy: 92671/110000 (84.25%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0073, Accuracy: 94955/110000 (86.32%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0066, Accuracy: 97009/110000 (88.19%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0071, Accuracy: 95000/110000 (86.36%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0066, Accuracy: 96789/110000 (87.99%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0065, Accuracy: 96817/110000 (88.02%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0048, Accuracy: 100215/110000 (91.10%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0049, Accuracy: 100153/110000 (91.05%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0055, Accuracy: 98644/110000 (89.68%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0053, Accuracy: 98700/110000 (89.73%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0052, Accuracy: 99228/110000 (90.21%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0052, Accuracy: 99707/110000 (90.64%)\n",
            "\n",
            "best top1 acc(%):  91.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model with `Deformable Convolution`"
      ],
      "metadata": {
        "id": "ei138pN6iG3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "batch_size = 64\n",
        "lr=1e-3\n",
        "gamma=0.7\n",
        "epochs=14\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "train_transform = transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "dataset1 = datasets.MNIST('./data', train=True, download=True,\n",
        "                    transform=train_transform)\n",
        "dataset2 = datasets.MNIST('./data', train=False,\n",
        "                    transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset1, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset2, batch_size=64, shuffle=True)\n",
        "\n",
        "model = MNISTClassifier(deformable=True).to(device)\n",
        "optimizer = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=gamma)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "best_test_acc = 0.\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(model, loss_function, device, train_loader, optimizer, epoch)\n",
        "    best_test_acc = max(best_test_acc, test(model, loss_function, device, test_loader))\n",
        "    scheduler.step()\n",
        "print(\"best top1 acc(%): \", f\"{best_test_acc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ6d-abO5aAe",
        "outputId": "238c9706-38dd-463f-fae2-0762de8b9e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0081, Accuracy: 90840/110000 (82.58%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0050, Accuracy: 99038/110000 (90.03%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0052, Accuracy: 98527/110000 (89.57%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0049, Accuracy: 98472/110000 (89.52%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0040, Accuracy: 101383/110000 (92.17%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 103336/110000 (93.94%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0040, Accuracy: 101391/110000 (92.17%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0038, Accuracy: 100963/110000 (91.78%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0051, Accuracy: 98852/110000 (89.87%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 103520/110000 (94.11%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0037, Accuracy: 101838/110000 (92.58%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0039, Accuracy: 101454/110000 (92.23%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0035, Accuracy: 101813/110000 (92.56%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0034, Accuracy: 102421/110000 (93.11%)\n",
            "\n",
            "best top1 acc(%):  94.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Theory Questions"
      ],
      "metadata": {
        "id": "hR_4hoCG0aD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theroy Question 1\n",
        "\n",
        "Here are some key differences in terms of grid sampling:\n",
        "\n",
        "### Standard Convolution:\n",
        "- Fixed Grid Sampling: The convolutional filters follow a fixed grid pattern during the sampling process.\n",
        "- Limited Adaptability: Standard convolutions are less adaptable to variations and deformations in the input data.\n",
        "\n",
        "### Deformable Convolution:\n",
        "- Deformable Grid Sampling: The convolutional filters dynamically adjust their sampling grid based on the content of the input.\n",
        "- Increased Adaptability: Deformable convolutions can better capture deformable structures and intricate patterns in the data.\n",
        "\n",
        "### Comparison:\n",
        "- Complex Patterns: Deformable convolutions excel in capturing complex patterns and structures that may not align with a regular grid.\n",
        "- Adaptability: The adaptive grid in deformable convolutions allows them to better handle variations in object shapes and positions.\n",
        "- Improved Performance: In tasks where objects undergo deformations, deformable convolutions often lead to improved performance compared to standard convolutions."
      ],
      "metadata": {
        "id": "LtmY69Iz0si_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theroy Question 2\n",
        "\n",
        "Here's how Deformable Convolutional Networks enable flexibility in the presence of geometric transformations:\n",
        "\n",
        "1. Learnable Offsets:\n",
        "   - In deformable convolutional layers, instead of using a fixed grid for sampling, the network introduces learnable offsets.\n",
        "   - These offsets are essentially additional parameters that the network learns during training.\n",
        "   - The offsets determine how the convolutional filters sample input values, allowing them to adapt to geometric transformations.\n",
        "\n",
        "2. Spatial Sampling Grid Adaptation:\n",
        "   - Deformable convolutions allow each location in the feature map to have its own sampling grid.\n",
        "   - The sampling grid is adjusted based on the learned offsets, enabling the network to focus on relevant regions and adapt to spatial transformations.\n",
        "\n",
        "3. Localization of Features:\n",
        "   - Deformable convolutions enable the network to localize features more accurately, especially in the presence of deformations and variations in object shapes.\n",
        "   - The learnable offsets help the network concentrate on informative regions, improving the capture of geometrically transformed patterns.\n",
        "\n",
        "4. Improved Object Localization:\n",
        "   - Traditional convolutional layers might struggle with accurately localizing objects in the presence of geometric transformations.\n",
        "   - Deformable convolutions improve object localization by providing a mechanism for the network to adjust its receptive field dynamically.\n",
        "\n",
        "5. Enhanced Robustness:\n",
        "   - By allowing the convolutional filters to adapt to the input data's specific content, deformable convolutions enhance the robustness of the network to geometric transformations.\n",
        "   - This adaptability is particularly beneficial in tasks where objects may undergo various deformations or changes in appearance.## Theroy Question 2\n",
        "\n",
        "Here's how Deformable Convolutional Networks enable flexibility in the presence of geometric transformations:\n",
        "\n",
        "1. Learnable Offsets:\n",
        "   - In deformable convolutional layers, instead of using a fixed grid for sampling, the network introduces learnable offsets.\n",
        "   - These offsets are essentially additional parameters that the network learns during training.\n",
        "   - The offsets determine how the convolutional filters sample input values, allowing them to adapt to geometric transformations.\n",
        "\n",
        "2. Spatial Sampling Grid Adaptation:\n",
        "   - Deformable convolutions allow each location in the feature map to have its own sampling grid.\n",
        "   - The sampling grid is adjusted based on the learned offsets, enabling the network to focus on relevant regions and adapt to spatial transformations.\n",
        "\n",
        "3. Localization of Features:\n",
        "   - Deformable convolutions enable the network to localize features more accurately, especially in the presence of deformations and variations in object shapes.\n",
        "   - The learnable offsets help the network concentrate on informative regions, improving the capture of geometrically transformed patterns.\n",
        "\n",
        "4. Improved Object Localization:\n",
        "   - Traditional convolutional layers might struggle with accurately localizing objects in the presence of geometric transformations.\n",
        "   - Deformable convolutions improve object localization by providing a mechanism for the network to adjust its receptive field dynamically.\n",
        "\n",
        "5. Enhanced Robustness:\n",
        "   - By allowing the convolutional filters to adapt to the input data's specific content, deformable convolutions enhance the robustness of the network to geometric transformations.\n",
        "   - This adaptability is particularly beneficial in tasks where objects may undergo various deformations or changes in appearance."
      ],
      "metadata": {
        "id": "L2TAQeEG0twL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theroy Question 3\n",
        "\n",
        "Standard convolutional layers may face challenges when dealing with images containing objects with significant spatial changes, such as rotations or deformations. Here are some reasons why simple convolutional layers might encounter difficulties in handling such scenarios:\n",
        "\n",
        "1. Fixed Grid Sampling:\n",
        "   - Standard convolutions use a fixed grid for sampling input values.\n",
        "   - This fixed grid might not be suitable for capturing spatial variations or deformations in the input, especially when objects undergo significant transformations.\n",
        "\n",
        "2. Limited Receptive Field:\n",
        "   - Convolutional layers have a limited receptive field, meaning they only consider a local region of the input at a time.\n",
        "   - In the case of spatial transformations, the standard convolutional layers may not have a sufficient receptive field to capture the entire transformed object.\n",
        "\n",
        "3. Lack of Adaptability:\n",
        "   - Simple convolutional layers lack the ability to adapt to the specific content of the input data.\n",
        "   - In the presence of geometric transformations, a fixed convolutional grid may fail to align with the deformed structures, leading to suboptimal feature extraction.\n",
        "\n",
        "4. Loss of Spatial Information:\n",
        "   - Rotation or deformation can cause a loss of spatial information if the convolutional layer's receptive field is not large enough.\n",
        "   - Standard convolutions may struggle to maintain the spatial relationships between pixels, leading to a degradation in the network's ability to understand the transformed objects.\n",
        "\n",
        "5. Invariance to Translations Only:\n",
        "   - Simple convolutional layers are designed to be translation invariant, but they may lack the ability to handle more complex spatial transformations.\n",
        "   - While translation invariance is beneficial, it may not be sufficient when dealing with rotated or deformed objects.\n",
        "\n",
        "6. Difficulty in Object Localization:\n",
        "   - Standard convolutions might find it challenging to accurately localize objects when the objects undergo spatial changes.\n",
        "   - The fixed nature of the convolutional grid may result in imprecise object localization in the presence of significant transformations."
      ],
      "metadata": {
        "id": "B6n7MpBn0zt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theroy Question 4\n",
        "\n",
        "The offsets in Deformable Convolutional Networks (DCNs) are learnable parameters that are calculated during the training process through backpropagation."
      ],
      "metadata": {
        "id": "5YUZr4Yc07LN"
      }
    }
  ]
}